[{"content":"When developing APIs for services in a company with a large user base, scalability becomes a critical consideration. Scaling an API in production for such a company requires keeping certain fundamentals in mind. Today, I’ll discuss a few key points that you should also keep in mind when approaching this challenge. Here’s a breakdown of some key techniques and strategies you can use:\nAPI Optimizations Reduce Payload Size: Send only the necessary data in responses and avoid including unnecessary properties, as every byte contributes to network overhead, even if it’s just a single byte.\nResponse Compression: Enable compression techniques like Gzip or Brotli to reduce payload size and accelerate data transfer.\nPagination and Filtering: For large datasets, implement pagination and filtering mechanisms to limit the amount of data sent in a single request.\nStateless Applications: Design application servers to be stateless, processing only request-specific information without storing or persisting data locally. Persist state-related information, such as user authentication or preferences, externally using databases, in-memory caches (e.g., Redis).This approach ensures that application servers can be easily scaled up or down during deployment to handle varying request loads, improving flexibility, fault tolerance, and scalability.\nConcurrency: Leverage concurrency to optimize performance when handling multiple tasks simultaneously. For instance, if an API request requires data from two or more services, you can make those service calls concurrently instead of sequentially. This reduces the overall response time by executing tasks in parallel, making better use of system resources. Consider using gRPC for inter-service communication, as it provides efficient, low-latency, and strongly-typed communication between services in a microservices architecture.\nDatabase Optimizations Indexing: Ensure that all frequently queried columns are properly indexed. This helps speed up SELECT queries by reducing the amount of data scanned. Avoid unnecessary indexing so that your write performance does not become bottleneck. Always explain the high RPS queries before putting in production server.\nQuery Optimization: Avoid complex JOINs and subqueries that slow down read and write operations. Also select the columns that are needed, avoid using * even if you have fewer or single column. Use EXPLAIN to analyze query performance and look for slow points.\nUse Proper Data Types: Choose appropriate data types and sizes for database columns to minimize storage requirements and reduce overhead. For example, use TINYINT instead of INT for small numeric ranges, and VARCHAR with a defined maximum length instead of a generic TEXT column for variable-length strings. Avoid allocating unnecessary space by matching the data type to the actual range of values needed, which helps improve query performance and reduces memory and disk usage.\nAvoid N+1 Queries: This issue occurs when a query fetches a list of items (1 query), and for each item, another query is executed (N queries). For example, fetching a list of users and then querying their associated orders individually leads to N+1 queries. To prevent this, use techniques like eager loading (e.g., JOIN statements or SELECT \u0026hellip; IN queries) to retrieve related data in a single query. Avoiding N+1 queries reduces redundant database calls and significantly improves API response times.\nConnection Pooling: Manage and optimize database connections with a connection pool to handle high concurrency, avoiding excessive connection overhead. Close connections that are no longer in use, and tune timeout settings to manage idle connections efficiently.\nWorking with Active Data: Keep only active and frequently accessed data in your main database tables to maintain optimal query performance. Archive unnecessary or historical data to separate tables or storage systems to reduce table size and improve query efficiency. This practice helps minimize index and table scan times, ensuring faster reads and writes.\nPrecompute Data: Precompute data for complex or frequently used calculations and store the results in the database. This reduces the need for on-the-fly computations during queries, improving response times and lowering database load. Use techniques like materialized views, denormalized tables, or scheduled background jobs to prepare precomputed data, especially for reports, summaries, or analytics.\nPrimary-Replica Setup: Use a primary-replica (master-slave) setup where the primary database handles writes, and replicas handle read traffic. Load balancers or application logic can direct read requests to replicas and write requests to the primary.\nRead Replicas: Distribute read requests across multiple read replicas to scale horizontally and reduce read latency.\nPartitioning: Partition tables based on certain fields (e.g., date, location) to split large tables into smaller, more manageable parts. This speeds up both reads and writes.\nCaching Layers Application-Level Caching: Implement caching at the application level for calculated or expensive operations. For instance, cache results of computationally intensive tasks or external API responses in memory or a caching system. Use Redis or Memcached to cache frequent reads. This offloads load from the database for common queries and reduces latency. Use Write-Through and Write-Behind caching techniques to keep cache and database in sync. Write-through writes data to both cache and database synchronously, while write-behind writes data to the cache immediately but updates the database asynchronously.\nHTTP Caching: Leverage HTTP caching headers like ETag(Entity Tag), Last-Modified, and Cache-Control to minimize redundant data transmission. For example, when a client requests a resource, the server returns an ETag as a unique identifier (e.g., a hash of the file or response\u0026rsquo;s contents) for the resource’s current state. On subsequent requests, the client includes the ETag in the If-None-Match header. If the resource hasn’t changed, the server responds with a 304 Not Modified status, skipping the resource data transfer entirely. This approach is particularly effective for reducing bandwidth usage and improving response times for APIs, especially when dealing with large payloads or frequently accessed resources.\nOptimizing Writes Batching and Bulk Operations: Instead of writing one row at a time, batch inserts, updates, or deletes into bulk operations. Many RDBMS systems optimize for bulk operations, which reduces transaction overhead.\nAsynchronous Writes: Offload non-critical writes, such as logging, analytics, or bulk update requests, to message queues like RabbitMQ or Kafka. Process these writes asynchronously using background job workers, ensuring they are written at a pace that aligns with the database’s capacity.\nDebouncing and Throttling: For high-frequency writes (e.g., metrics or real-time events), use debouncing or throttling to limit writes per second or group them before committing.\nHorizontal Scaling Sharding: Divide the data into smaller, more manageable databases (shards) based on some criteria (e.g., user ID, geo location). Sharding reduces the size of each database, helping maintain performance at scale.\nMicroservices with Independent Databases: If you’re using a microservices architecture, each service can have its database. This ensures that high read/write loads for one service do not affect others. Distribute incoming API requests across multiple servers using a load balancer to avoid overloading a single server and ensure high availability. In modern systems, tools like Kubernetes and container orchestration platforms make managing such architectures easier. They enable seamless scaling, deployment, and high availability by distributing API requests across multiple service instances using load balancers.\nAPI Rate Limiting and Throttling API Gateway: Use an API gateway to centralize tasks like routing, authentication, rate limiting, caching, and monitoring. Tools like Kong, Traefik can effectively manage API traffic. The gateway can cache responses at the edge, allowing faster response times by serving data from the cache, reducing load on backend services.\nRate Limiting: Set limits on API requests to prevent abuse and reduce excessive database loads. Implement IP-based rate limiting or user-based quotas.\nBackpressure Mechanism: For high-traffic APIs, implement backpressure strategies (like retry with exponential backoff) to prevent overloading your database.\nMonitoring and Tuning Database Monitoring: Use monitoring tools (e.g., Prometheus, Grafana, or APM tools like Datadog) to track query performance, slow queries, CPU, memory usage, and I/O operations.\nLoad Testing: Perform load and stress testing to identify bottlenecks and tune settings before the system goes live. Tools like Apache JMeter, Tsung and k6 can be helpful.\nTracing Tools: Use tools like OpenTelemetry (Otel) for API tracing to identify bottlenecks and performance issues in your APIs. Tracing helps you monitor and analyze the flow of requests across services, pinpointing delays or errors caused by downstream or upstream dependencies, such as network latency, service timeouts, or database query slowness. By integrating tracing into your system, you can gain valuable insights into your API’s behavior and resolve issues efficiently.\nBy following these steps, you can effectively manage large read and write operations in your REST API with an RDBMS, ensuring that it scales to meet demand while maintaining performance.\nEngineering is all about tradeoffs, so before optimizing or scaling, it’s essential to assess your needs and the specific situation.\n","permalink":"https://devrx.io/posts/scalability-essentials-for-apis-in-high-traffic-services/","summary":"\u003cp\u003eWhen developing APIs for services in a company with a large user base\u003c!-- raw HTML omitted --\u003e, scalability becomes a critical consideration. Scaling an API in production for such a company requires keeping certain fundamentals in mind. Today, I’ll discuss a few key points that you should also keep in mind when approaching this challenge.\nHere’s a breakdown of some key techniques and strategies you can use:\u003c/p\u003e\n\u003ch3 id=\"api-optimizations\"\u003eAPI Optimizations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eReduce Payload Size:\u003c/strong\u003e Send only the necessary data in responses and avoid including unnecessary properties, as every byte contributes to network overhead, even if it’s just a single byte.\u003c/p\u003e","title":"Scalability Essentials for APIs in High-Traffic Services"},{"content":"In today’s world, scalability is a common challenge that most of us face when developing applications. To scale out and build easily manageable services, we often break down a system\u0026rsquo;s responsibilities into multiple microservices. In a microservices architecture, each service manages its own database, and the type of database can differ between services. This diversity complicates implementing a two-phase commit, and in many cases, services don’t always require strong consistency.\nHTTP Call to Update Inventory (Service Unavailable)\nLet’s explore this issue using an example of an e-commerce platform, where we might have an order service and an inventory service. When a user places an order, the order service creates an entry in its database and needs to update the product inventory once the payment is successfully processed.\nSince these are two separate services, potentially managed by different teams, one might use a relational database like PostgreSQL, while the other could rely on a NoSQL database like MongoDB.\nWhen placing an order, we know the operation must be handled as a transaction. The order cannot be placed without updating the inventory, and the inventory cannot be updated without placing the order.\nBefore going further, we need to understand what is transaction? Well, transaction is a sequence of operations performed as a single logical unit of work, ensuring atomicity, consistency, isolation and durability, either complete success or full rollback. These properties are available in relational databases like MySQL and PostgreSQL to maintain data consistency. ACID supported relational databases generally uses 2PC (two phase commit) to ensure strong consistency. However, in distributed systems this is more complex and harder to achieve.\nTo manage transactions in distributed systems, we can utilize the Saga pattern. In our previous article, we explored how distributed services interact through Choreography and Orchestration , as well as how to ensure data integrity and consistency using the Outbox pattern.\nThe Saga pattern can be implemented in two ways: one approach involves a central orchestrator managing the transaction lifecycle, while the other relies on choreography. Let’s delve into both approaches of the Saga pattern using real-life examples.\nSaga Orchestration Saga orchestration is a pattern used to manage transactions that span multiple microservices. Instead of relying on traditional distributed transactions (which are difficult to implement in microservices due to their independence), a saga splits the transaction into smaller, local transactions. Each service performs its task and then informs a central Orchestrator, which coordinates the workflow.\nIf one service fails, the orchestrator triggers compensating actions to undo the work of previous services, ensuring consistency across the system. This rollback mechanism is essential in ensuring the system does not leave the platform in an inconsistent state when something goes wrong.\nHandling Distributed Transactions in the Event of a Local Transaction Failure\nIn an e-commerce system, the process to place an order spans multiple services. The Order Service handles the order placement, followed by the Payment Service for processing payment. Once the payment is successful, the Inventory Service updates stock, and finally, the Notification Service sends an email to inform the user about the order status.\nThese services need to interact in a sequence to complete an order, and if something fails (for example: Inventory service failed), the system needs to gracefully roll back the transaction. Here’s how saga orchestration ensures smooth operation.\nStep-by-Step Workflow:\nOrder Creation When a customer places an order, the first step in the workflow is creating the order in the system. The Order Service receives the request, creates a new order record, and marks the order as \u0026ldquo;PENDING\u0026rdquo; until the payment is processed.\nOnce the order is created, the Orchestrator is notified and takes control of the workflow. It then instructs the next microservice, the Payment Service, to process the payment for the order.\nPayment Processing The Payment Service is responsible for charging the customer’s payment method. This could involve processing a credit card, using a third-party payment gateway, or another form of transaction.\nIf the payment is successful, the Payment Service informs the Orchestrator, and the transaction continues to the next step. However, if the payment fails—perhaps due to insufficient funds or a payment gateway error—the orchestrator is immediately notified, and the saga begins its compensation process.\nUpdate inventory Once the payment is successful, the orchestrator will update the inventory and reduce the product stock quantity.\nSending Notifications Assuming the previous steps succeeded, the next step is to notify the customer that their order has been successfully placed. The Orchestrator instructs the Notification Service to send an order confirmation email or SMS to the customer.\nThis step completes the transaction. Once the notification is sent, the orchestrator updates the status of the order from \u0026ldquo;PENDING\u0026rdquo; to \u0026ldquo;COMPLETED,\u0026rdquo; and the saga ends successfully. Note: we can update the state to \u0026lsquo;COMPLETED\u0026rsquo; based on the previous step as notification can be optional in terms of this transaction.\nHandling Failures and Rollbacks Failures in any distributed system are inevitable. With the saga orchestration pattern, handling these failures becomes much more manageable. Let’s explore what happens when things don’t go as planned.\nPayment Failure: If the Payment Service fails to process the payment (due to a technical issue or insufficient funds), the orchestrator will initiate the compensation process. This means the Order Service will be asked to cancel the order, update its status to \u0026ldquo;CANCELED,\u0026rdquo; this leads to trigger compensationary transaction C2-\u0026gt;C1.\nThe customer is not charged, and no notification is sent since the order did not go through. The orchestrator logs the failure, ensuring that the platform is aware of the unsuccessful transaction.\nInventory Failure: In the event that the Inventory Service fails to reduce the stock, it triggers a compensation process (C3) that cascades through the transaction, leading to C2 (refund payment) and C1 (cancel order). However, one crucial point to keep in mind is that each service must implement a retry mechanism. This ensures that temporary issues, such as network glitches or momentary downtime, do not result in immediate failure. By retrying, services can attempt to complete their tasks before reporting a failure, minimizing unnecessary rollbacks and ensuring smoother transaction flow.\nNotification Failure: If the Notification Service fails (e.g., due to an issue with the email provider), the orchestrator might not need to roll back the entire transaction. Instead, it can log the failure and notify the system administrator that the customer wasn’t informed of the order. This is a non-critical error that can be handled separately from the core transaction.\nCan we effectively manage these states and their transitions based on different inputs? Yes, By modeling the process using a Finite State Machine (FSM). FSM allows us to define each state—such as order placement, payment processing, inventory update, and notification—and map the transitions between them. These transitions are triggered by inputs like Success or Failure at each step. For example, if payment is successful, the FSM moves to the inventory update step; if a failure occurs, it triggers a transition to the appropriate compensation actions. This structured approach helps manage complex workflows efficiently.\nCurrent State Input/Condition Next State Action Order Created (T1) Success Payment Processing (T2) Proceed to payment processing Order Created (T1) Failure Compensation (C1) Cancel the order (C1) Payment Processing (T2) Success Inventory Update (T3) Proceed to inventory update Payment Processing (T2) Failure Compensation (C2, C1) Refund payment (C2) and cancel the order (C1) Inventory Update (T3) Success Completion Complete the order Inventory Update (T3) Failure Compensation (C3, C2, C1) Restore inventory (C3), refund payment (C2), cancel the order (C1) Saga Choreography In the Saga choreography pattern, there is no central orchestrator or coordinator to control the flow of transactions. Instead, services communicate through a message queue or an event bus. Each service listens for specific events or topics and reacts accordingly. Once a service completes its task, it publishes an event or command to signal the next service to continue the process.\nThis decentralized approach allows each service to handle its own part of the transaction independently. For instance, after the Order Service creates an order, it publishes an event. The Payment Service listens for that event, processes the payment, and then publishes another event for the Inventory Service to update stock. The flow continues in this manner, with each service both reacting to and publishing events to move the transaction forward.\nHandling Distributed Transactions through Decentralized Event-Driven Choreography\nLet’s break down the step-by-step flow of choreography using the Order, Payment, and Inventory services. Each service communicates through events without a central orchestrator, making this an event-driven transaction management system.\nStep-by-Step Workflow:\nOrder Creation Customer places an order and the Order Service processes the order and creates an entry for it. Once the order is successfully created, the service publishes an event called ORDER_CREATED to notify other services.\nPayment Processing The Payment Service listens for the ORDER_CREATED event. Upon receiving it, the Payment Service initiates the payment process (e.g., charging the customer’s credit card). If the payment is successful, the Payment Service publishes a PAYMENT_COMPLETED event, otherwise the service publishes a PAYMENT_FAILED event, which can trigger a rollback (e.g., cancel the order).\nInventory Update The Inventory Service listens for the PAYMENT_COMPLETED event. When it receives this event, it reduces the stock of the items in the order. If the stock is successfully updated, the Inventory Service publishes an STOCK_UPDATED event to continue the transaction flow. If the stock update fails (e.g., insufficient stock), it publishes a STOCK_UPDATE_FAILED event. This event can trigger compensating actions like issuing a refund and canceling the order.\nSening Notifications The Notification Service listens for the STOCK_UPDATED event. When it receives the event, it sends a confirmation email to the customer, notifying them that their order is complete and ready for shipment. If there were earlier failures (e.g., payment or inventory update failures), the Notification Service can also listen to failure events like PAYMENT_FAILED, STOCK_UPDATE_FAILED or only ORDER_FAILED, notifying the customer about the failure and status of their order.\nHandling Failures and Rollbacks If a failure occurs at any step, such as payment failure or inventory update failure, compensating transactions are triggered via published failure events:\nIf the Payment Service fails to process the payment, it publishes a PAYMENT_FAILED event. The Order Service listens to this event and cancels the order. If the Inventory Service cannot update the stock, it publishes an STOCK_UPDATE_FAILED event, which triggers a refund in the Payment Service and order cancellation in the Order Service.\nTrade-offs Between Saga Orchestration and Choreography When designing distributed systems, choosing between saga orchestration and saga choreography depends on various factors such as complexity, performance, and the flexibility of your architecture.\nOrchestration offers centralized control, making it easier to manage complex workflows, but this can lead to tighter coupling and potential bottlenecks.\nChoreography promotes loose coupling and flexibility, which allows for better scalability and resilience but increases the complexity of managing distributed events and tracking the workflow. Your decision should be based on the specific requirements of your system, including how critical centralized control, flexibility, and scalability are to your application’s success.\nFor deeper understanding of the interaction mechanisms in distributed systems, please go through my previous article on choreography and orchestration\n","permalink":"https://devrx.io/posts/distributed-transaction-with-saga-pattern/","summary":"\u003cp\u003eIn today’s world, scalability is a common challenge that most of us face when developing applications. To scale out and build easily manageable services, we often break down a system\u0026rsquo;s responsibilities into multiple microservices. In a microservices architecture, each service manages its own database, and the type of database can differ between services. This diversity complicates implementing a two-phase commit, and in many cases, services don’t always require strong consistency.\u003c/p\u003e","title":"Handling Distributed Transactions: A Deep Dive into the Saga Pattern"},{"content":"In an e-commerce application, when a customer places an order, it is common to need to send an order_placed event to an event bus for further processing. A straightforward approach would be to make an entry in the order table and then publish the event synchronously. However, this raises significant concerns regarding the availability and reliability of the event bus.\nMessage queue is unavailable while placing order\nFor instance, what happens if the event bus is not available at the moment of publishing? In this case, one might consider rolling back the transaction in the order service to ensure that the order is not created without the corresponding event being sent. This rollback, however, introduces a delay in the user experience and creates a tight coupling between the order creation and event publishing processes.\nSimilarly, if the order service writes to the order table and simultaneously sends an HTTP request to the inventory service to update inventory levels, what if the inventory service is down? This creates another point of temporal coupling, where the success of the order placement is dependent on the availability of the inventory service. If the inventory service fails to respond, it could lead to inconsistent states between the order and inventory systems.\nCan we solve this dual write issue by using Outbox Pattern? Answer is Yes, lets learn about it in details.\nWhat is outbox pattern? The Outbox Pattern is a design pattern used in distributed systems, particularly in microservices architecture, to ensure reliable message delivery while maintaining data consistency between different services. Here’s a detailed breakdown of the Outbox Pattern, its use cases, and how it can be implemented.\nIn microservices, it’s common for a service to need to send messages to other services, often via a message broker (like RabbitMQ, Kafka, etc.) or to an event bus. However, ensuring that the message is sent reliably while maintaining consistency with the primary data store can be challenging. The Outbox Pattern addresses this challenge by utilizing a single database transaction to handle both the writing of the data and the message.\nHow It Works?\nPublishing events/messages using Outbox Pattern\nOutbox Table: An additional table (the outbox table) is created in the same database where the service stores its primary data. This table is used to store messages that need to be sent. Single Transaction: When a service performs a business operation that requires sending a message, it writes both the business data and a message record into the outbox table in a single transaction. This ensures that either both actions succeed or neither does, thus maintaining consistency. Message Dispatcher: A separate process (often a background worker or a scheduled task) is responsible for reading the messages from the outbox table and sending them to the appropriate message broker or downstream service. After successfully sending the message, the dispatcher can mark the message as sent or remove it from the outbox table. Idempotency: To handle the possibility of the message being sent more than once (due to retries or failures), the design should ensure that the operations in the receiving service are idempotent. How to Implement it?\nDefine the Outbox Table: Create a table structure that includes fields such as id, event_type, payload, priority, created_at, and processed_at. Write to Outbox: Within your service method, after modifying the main entity, insert a record into the outbox table within the same transaction. Message Dispatcher: Implement a background service or scheduled job that polls the outbox table for new messages, sends them to the message broker, and marks them as processed. Error Handling and Retries: Implement error handling and retries in the message dispatcher to handle transient failures while sending messages. Idempotency: Ensure that the receiving service can handle duplicate messages without adverse effects, typically by using unique identifiers for each message. Let\u0026rsquo;s go back to the e-commerce application where a customer places an order.\nThe order service needs to:\nUpdate the order status in the database. Send an event to a message broker to notify other services (like inventory and billing). Using the Outbox Pattern, the order service would:\nUpdate the order status and insert a record in the outbox table with the event details in one transaction. A separate process reads from the outbox, sends the event to the message broker, and updates the outbox table to mark the event as processed. Where to use Outbox pattern? Event-Driven Architectures: In scenarios where services need to communicate asynchronously through events (e.g., user registrations, order processing), the Outbox Pattern ensures that events are not lost even if the sending process fails. Transactional Outbox: When performing operations that need to be atomic (e.g., updating a user profile and notifying other services), the Outbox Pattern guarantees that both the data change and the event are either committed together or not at all. This is essential for applying distributed transaction while performing Saga pattern. Consistency Across Services: In scenarios where data consistency is critical (e.g., financial transactions), the Outbox Pattern helps maintain consistency (eventual consistency) between different services by ensuring that the message is only sent if the data update was successful. Microservices Communication: The pattern is beneficial in microservices architectures where inter-service communication is frequent, and data synchronization across services is essential. Now that we understand when to use the Outbox Pattern, let’s explore its advantages and challenges.\nAdvantages\nReliability: Guarantees that messages are not lost and are sent only once. Atomicity: Ensures that the write to the database and the message dispatch happen atomically. Decoupling: Keeps the sending logic separate from the business logic, promoting cleaner code and better separation of concerns. Failure Recovery: Provides a mechanism for recovering from failures since the messages remain in the outbox until they are successfully sent. Challenges:\nIncreased Complexity: Implementing the Outbox Pattern can add complexity to your system, particularly in managing the outbox processing mechanism. Database Load: Continuously polling the outbox table may introduce additional load on the database, especially in high-throughput systems. Idempotency: Consumers of the outbox messages need to be designed to handle potential duplicates gracefully. The Outbox Pattern is a powerful solution for ensuring reliable message delivery and maintaining data consistency in microservices architectures. By leveraging a transactional outbox, it helps avoid the pitfalls of distributed systems, such as lost messages and inconsistent state across services.\n","permalink":"https://devrx.io/posts/mastering-microservics-ensuring-data-consistency-with-the-outbox-pattern/","summary":"\u003cp\u003eIn an e-commerce application, when a customer places an order, it is common to need to send an \u003ccode\u003eorder_placed\u003c/code\u003e event to an event bus for further processing. A straightforward approach would be to make an entry in the \u003ccode\u003eorder table\u003c/code\u003e and then publish the event synchronously. However, this raises significant concerns regarding the availability and reliability of the event bus.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/media/posts/mastering-microservics-ensuring-data-consistency-with-the-outbox-pattern/outbox-pattern-1.svg\"\n         alt=\"outbox-pattern-diagram\"/\u003e \u003cfigcaption\u003e\n            \u003cp\u003eMessage queue is unavailable while placing order\u003c/p\u003e\n        \u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eFor instance, what happens if the event bus is not available at the moment of publishing? In this case, one might consider rolling back the transaction in the \u003ccode\u003eorder service\u003c/code\u003e to ensure that the order is not created without the corresponding event being sent. This rollback, however, introduces a delay in the user experience and creates a tight coupling between the order creation and event publishing processes.\u003c/p\u003e","title":"Mastering Microservices: Ensuring Data Consistency with the Outbox Pattern"},{"content":"In Choreography, dancers perform independently based on cues or signals from each other, without a central leader directing them. Each dancer knows their part and reacts to the movements or signals from others, much like how microservices communicate through events. The performance unfolds naturally as each dancer responds to the rhythm and flow.\nDancers performing choreography in sync with the music\nIn Orchestration, however, a conductor leads the musicians, directing them when to start, stop, or change tempo. The conductor has full control over the entire performance, much like how an orchestrator in microservices coordinates each service, managing the flow and ensuring everything happens in the right sequence.\nOrchestra managing the musicians\nAs companies transition from monolithic applications to microservices, managing service interactions becomes more complex. One of the critical decisions in designing microservices is how to coordinate interactions between services. Two prominent patterns—Choreography and Orchestration—have emerged as solutions for managing these interactions. In this post, we’ll dive into the differences between Choreography and Orchestration with examples from a ride-sharing service, helping you understand which pattern fits different situations.\nRecap: What Are Microservices? Microservices are an architectural style where large applications are composed of small, independent services that work together to fulfill business requirements. Each service performs a specific business function, like user management, payment processing, or location tracking. This decoupling improves scalability and resilience but introduces complexity, especially in managing communication between services.\nChoreography vs Orchestration in a Microservices Architecture In microservices, how you design service-to-service communication can make or break your system\u0026rsquo;s scalability, maintainability, and resilience. Two common patterns to coordinate service interactions are:\nOrchestration: A central controller or orchestrator manages and directs services. Choreography: Services interact through decentralized, event-driven communication. To better understand these patterns, let’s consider a ride-sharing service like Uber or Lyft as a practical example.\nOrchestration in a Ride-Sharing Service In an orchestrated architecture, a central component manages the flow of operations between services. Imagine a scenario where a user books a ride through a ride-sharing app. An orchestrator would manage the entire booking process, coordinating interactions between the services involved.\nOrchestrator coordinating HTTP calls among microservices\nExample: Booking a Ride Using Orchestration\nIn this example, the orchestrator would manage the sequence of actions:\nRide Booking Request: The orchestrator receives a request to book a ride from the user. The orchestrator first checks for available drivers using the Driver Service. Fare Calculation: After finding available drivers, the orchestrator calculates the estimated fare by invoking the Fare Calculation Service. Payment Authorization: The orchestrator then contacts the Payment Service to authorize the payment based on the estimated fare. Notification: Once the payment is authorized, the orchestrator informs the Notification Service to send a confirmation message to both the driver and the passenger. Driver Assignment: Finally, the orchestrator assigns the driver to the passenger, completing the booking. The orchestrator knows every step of the process, executes each service in the required order, and handles failure recovery if something goes wrong.\nAdvantages of Orchestration: Centralized Control: The orchestrator knows the entire workflow and manages each step. This allows easy monitoring and management of complex workflows. Simplified Services: Each service is responsible for a single task, relying on the orchestrator to manage interactions. Easier Error Handling: The orchestrator can handle retries and compensation logic when a service fails.\nDrawbacks of Orchestration: Single Point of Failure: The orchestrator becomes a central point that must be highly available and scalable. Tight Coupling: Services are coupled to the orchestrator, making it harder to scale services independently. Bottleneck Potential: In high-traffic systems, the orchestrator may become a bottleneck if not designed to handle significant loads.\nChoreography in a Ride-Sharing Service In contrast to Orchestration, Choreography is a decentralized approach where services interact through events without a central controller. Each service performs its task and emits an event that other services can react to, creating an event-driven flow of operations.\nServices reacting to events in a choreography pattern\nExample: Booking a Ride Using Choreography\nHere’s how Choreography would work in the same ride-booking process:\nRide Booking Request: The User Service receives a ride request and publishes an event, RideRequested. Driver Availability: The Driver Service listens to the RideRequested event and checks for available drivers. Once a driver is found, it publishes an event, DriverAssigned. Fare Calculation: The Fare Calculation Service listens to the DriverAssigned event and calculates the fare. It then emits a FareCalculated event. Payment Authorization: The Payment Service listens to the FareCalculated event and authorizes the payment. After successful authorization, it emits a PaymentAuthorized event. Notification: The Notification Service listens to the PaymentAuthorized event and sends notifications to the driver and passenger about the confirmed ride. Each service reacts to specific events and performs its task without relying on a central orchestrator. Also keep in mind to apply Outbox Pattern for publishing events.\nAdvantages of Choreography:\nLoose Coupling: Services are loosely coupled as they only communicate via events, allowing them to scale independently and evolve without breaking the system. Scalability: Services can scale horizontally based on event volume. There’s no central orchestrator to become a bottleneck. Fault Isolation: Failures in one service don’t cascade to other services, as each service operates independently. Drawbacks of Choreography:\nComplex Debugging: Since there’s no central controller, it can be challenging to trace the flow of events and identify where something went wrong. Event Storms: If not designed carefully, events can multiply and create a storm of messages across services. Implicit Workflows: The overall workflow isn’t explicitly defined anywhere; instead, it emerges from the interaction between services, which can make it harder to maintain and reason about the system. Choosing Between Orchestration and Choreography Deciding between Orchestration and Choreography isn’t straightforward. The choice depends on your use case, system complexity, and team expertise. Below are some considerations to help guide your decision.\nWhen to Use Orchestration? Complex, Linear Workflows: If your business process is complex with multiple steps and strict sequencing, Orchestration provides better control and visibility. Centralized Error Handling: If error handling is critical (e.g., handling payment failures or order cancellations), Orchestration gives you the flexibility to retry or compensate. Simpler Service Design: If you want services to focus on single tasks and leave the coordination to an external component, Orchestration simplifies the service logic. When to Use Choreography? Decentralized, Event-Driven Systems: If your system is naturally event-driven (e.g., you are using event sourcing or CQRS), Choreography fits naturally. Scalability: If scaling independently is important for your system (e.g., driver assignment in a high-traffic scenario), Choreography allows services to grow without becoming bottlenecks. Flexibility: When you want services to evolve independently without being tightly coupled to a central orchestrator, Choreography gives you more freedom. A Hybrid Approach: The Best of Both Worlds\nIn many real-world systems, a hybrid approach works best. You can combine both Orchestration and Choreography to manage different levels of workflow complexity. For instance:\nHigh-level orchestration can manage major workflows like ride booking, payments, and ride completion. Choreographed event-driven services can handle low-level tasks like sending notifications, logging, or updating driver and passenger statuses. Understanding Choreography and Orchestration is crucial for designing efficient, scalable microservice architectures. Orchestration offers centralized control, error handling, and workflow visualization, while Choreography enables decoupled, scalable, and resilient service interactions.\nFor a ride-sharing service, you could use Orchestration to manage critical, sequential tasks like payments and ride assignments, while using Choreography for more loosely coupled components like notifications or logging.\nUltimately, the decision depends on your application’s needs. Both patterns can coexist in a well-architected system to handle different aspects of your microservices, giving you the best of both worlds.\n","permalink":"https://devrx.io/posts/mastering-microservices-battle-between-choreography-and-orchestration/","summary":"\u003cp\u003eIn \u003cem\u003e\u003cstrong\u003eChoreography\u003c/strong\u003e\u003c/em\u003e, dancers perform independently based on cues or signals from each other, without a central leader directing them. Each dancer knows their part and reacts to the movements or signals from others, much like how microservices communicate through events. The performance unfolds naturally as each dancer responds to the rhythm and flow.\u003c/p\u003e\n\u003cfigure\u003e\n    \u003cimg loading=\"lazy\" src=\"/media/posts/mastering-microservices-battle-between-choreography-and-orchestration/Choreography.svg\"\n         alt=\"Choreography-diagram\"/\u003e \u003cfigcaption\u003e\n            \u003cp\u003eDancers performing choreography in sync with the music\u003c/p\u003e\n        \u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eIn \u003cem\u003e\u003cstrong\u003eOrchestration\u003c/strong\u003e\u003c/em\u003e, however, a conductor leads the musicians, directing them when to start, stop, or change tempo. The conductor has full control over the entire performance, much like how an orchestrator in microservices coordinates each service, managing the flow and ensuring everything happens in the right sequence.\u003c/p\u003e","title":"Mastering Microservices: The Battle Between Choreography \u0026 Orchestration"},{"content":"The way you communicate, Does It Affect Your Way of Life?\nCertainly it does, communication is essential for understanding each other; nearly every living organism relies on it. While that’s not our topic today, it’s crucial to consider how communication impacts distributed systems.\nSo, what happens when hundreds of services need to interact with each other? How do you manage this in your daily work? Are your services becoming overly chatty and tangled, like a plate of spaghetti?\nMicroservices can utilize both synchronous and asynchronous approaches depending on their use cases. For synchronous communication, options like REST APIs and gRPC are commonly used. In contrast, asynchronous communication often involves messaging such as events and commands with a proper message queue or pub/sub mechanism. We’ll explore these concepts further, including choreography and orchestration, in our next article.\nLet\u0026rsquo;s consider services such as Order, History, and Payment from an e-commerce platform. Taking a simple, straightforward approach:\nServices interconnected via HTTP calls, creating a tangled network\nWhen a user places an order, the Order service inserts a new record into its database with the status ‘Payment Pending’. The Order service then makes a request to the History service via REST API or gRPC to log the order, with a message like ‘Order XYZ placed’. Next, the Order service sends a request to the Payment service to generate an invoice for the order. The user is redirected to the payment page. Once the payment is successfully processed, the Payment service handles its internal business logic. After the payment is completed, the Payment service must notify the Order service to update the order status and send another request to the History service to log the successful payment against the order. The key point here is that microservices are designed based on their specific responsibilities. However, when implementing a single flow, such as Place a New Order, we often find ourselves making synchronous calls between services, creating a complex web of dependencies. This can resemble a tangled bowl of noodles, where it’s unclear which service is calling which and why.\nConsider the following issues with previous approach:\nService Dependencies and Failures: If the History service is temporarily down, the Order service's synchronous call to it will fail, potentially causing the entire order placement process to fail. This is because the Order service is making HTTP or gRPC requests to both the History and Payment services, resulting in a request/response interaction.\nService Latency: What if all services are operational but one of them is experiencing latency? Should the Order service fail the order placement due to the delay, or should it wait for the slow History service response? This introduces a challenge in balancing timely order processing with handling slow responses from dependent services.\nPrioritization of Services: From a business perspective, the placement of an order is crucial because it directly impacts revenue. In contrast, updating the History service can be less time-sensitive. Thus, the Order service should prioritize completing the order placement process and consider deferring or handling the history update at a later time if necessary.\nExploring an Alternative Approach Instead of making synchronous HTTP REST API or gRPC calls between services, we can leverage a message queue for communication:\nPublish Events and Commands:\nPublish an order_created event with relevant order details. Publish a process_payment command with the necessary payment information. Implement the Outbox Pattern to ensure that these messages are published as part of the same transaction as the order creation. Services responding to events at their own pace asynchronously\nWhat happens on the subscriber’s end?\nHistory Service: Listens for the order_created event at its own pace and updates its records accordingly. Payment Service: Listens for the process_payment command and performs the payment processing logic. Post-Payment Processing: Once the user is redirected to the payment page and successfully completes the payment, the Payment Service publishes a payment_successful event or, if the payment fails, a payment_failed event. Updating Records: Upon receiving the payment_successful or payment_failed event, both the Order Service and History Service can update their records to reflect the final status of the order. Trade-offs between Messaging \u0026amp; Request/Response approach Advantages of Messsging:\nAsynchronous Communication: Services can communicate without waiting for an immediate response, reducing latency and improving responsiveness. Decoupling: Services are loosely coupled, as they don’t need to know about each other\u0026rsquo;s implementation details. This allows for more flexible scaling and maintenance. Resilience and Fault Tolerance: If a service is down or experiencing slow performance, messages can be queued and processed later, thereby mitigating the impact of service failures. Services can process messages at their own pace and according to their processing capacity, allowing for better handling of varying loads and system resilience. Scalability: Supports high scalability, as multiple consumers can process messages from the queue concurrently. Flexibility: Easy to implement event-driven architectures, allowing services to react to events in a decoupled manner. Disadvantages Messaging:\nComplexity: Introduces additional complexity in managing message queues, ensuring message delivery, and handling retries and failures. Latency: May introduce some latency due to message queuing and asynchronous processing. Message Ordering: Ensuring the correct order of message processing can be challenging. Debugging and Monitoring: Can be harder to debug and monitor compared to synchronous communication. Consistency: Managing consistency across services can be more complex, especially with eventual consistency models. Advantages of Request/Response:\nSimplicity: REST APIs are straightforward to implement and understand, using standard HTTP methods and status codes. Synchronous Communication: Provides immediate feedback and results, which can simplify error handling and transaction management. Interoperability: REST APIs are language-agnostic and can be easily consumed by various clients and services. Ease of Testing: Easier to test and debug due to synchronous request/response nature. Disadvantages of Request/Response:\nCoupling: Services are more tightly coupled, as they need to know about each other’s endpoints and data formats. Scalability: Can be less scalable due to synchronous communication, which may lead to bottlenecks under high load. Error Handling: Error handling can be more complex as failures in one service can affect the entire request flow. Latency: Can introduce latency due to the synchronous nature of communication, where services have to wait for each other’s responses. Reliability: If a service is down, the calling service may experience downtime or failures, affecting overall system reliability. Each approach has its own strengths and is suitable for different scenarios. The choice between Messaging and Request/Response often depends on the specific requirements of the system, such as the need for asynchronous processing, scalability, or real-time communication. In many real-world systems, a hybrid approach works best.\n","permalink":"https://devrx.io/posts/mastering-microservices-the-power-of-effective-communication/","summary":"\u003cp\u003e\u003cstrong\u003eThe way you communicate, Does It Affect Your Way of Life?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eCertainly it does, communication is essential for understanding each other; nearly every living organism relies on it. While that’s not our topic today, it’s crucial to consider how communication impacts distributed systems.\u003c/p\u003e\n\u003cp\u003eSo, what happens when hundreds of services need to interact with each other? How do you manage this in your daily work? Are your services becoming overly chatty and tangled, like a plate of spaghetti?\u003c/p\u003e","title":"Mastering Microservices: The Power of Effective Communication"},{"content":"In this tutorial, I’ll introduce you to an open-source tool that makes creating amazing API documentation effortless!\nIf you’re working with REST APIs and exposing them through HTTP/JSON, there’s a good chance you’re already using Postman to test, debug, and manage collections. When collaborating with teams, especially Android or iOS developers, you often need to share your API documentation. This typically involves sharing the Postman collection in JSON format along with manually written documentation to describe the API.\nTo eliminate the hassle of manual documentation, I built a command-line tool back in 2018 that automatically generates API documentation in HTML and Markdown formats. While there were other tools available at the time, I wanted something more tailored to my workflow, so I decided to create my own solution.\nWith this tool, generating API documentation from your Postman collection is simple and efficient. All you need to do is provide the necessary information, and the tool takes care of the rest. Let’s dive into how you can use Docgen to create your API documentation effortlessly.\nStep 1: Installing Docgen First, you’ll need to install Docgen on your computer. If you’re using macOS or Linux, you can install it by running the following command in your terminal:\ncurl https://raw.githubusercontent.com/thedevsaddam/docgen/v3/install.sh -o install.sh \u0026amp;\u0026amp; sudo chmod +x install.sh \u0026amp;\u0026amp; sudo ./install.sh For Windows users, you can download the binary directly from the Docgen GitHub repository.\nAfter completing the installation, you should see a confirmation message indicating that the installation was successful.\nStep 2: Export Your Postman Collection Next, export your Postman collection and save it as a JSON file. This file will act as the input for generating your API documentation.\nStep 3: Generate HTML or Markdown Documentation To generate HTML documentation, use the following command:\ndocgen build -i input-postman-collection.json -o ~/Downloads/index.html If you’d rather generate documentation in Markdown format, use the following command:\ndocgen build -i input-postman-collection.json -o ~/Downloads/index.md -m Preview Your Documentation with Docgen’s Live Server Docgen also includes a live server feature that lets you preview your API documentation in real-time, without the need to save the output file. This is especially useful when you want to quickly review the final result.\nFor more detailed instructions and additional features, visit the official Docgen GitHub page: https://github.com/thedevsaddam/docgen.\nWith Docgen, you can save time and streamline your API documentation process, making collaboration with your team more efficient!\nThis tool has been extremely helpful in my own projects, and I hope it proves useful to you as well. Give it a try, and feel free to let me know what you think!\n","permalink":"https://devrx.io/posts/postman-api-documentation-generator/","summary":"\u003cp\u003eIn this tutorial, I’ll introduce you to an open-source tool that makes creating amazing API documentation effortless!\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"api doc\" loading=\"lazy\" src=\"/media/posts/postman-api-documentation-generator/api-doc.png\"\u003e\u003c/p\u003e\n\u003cp\u003eIf you’re working with REST APIs and exposing them through HTTP/JSON, there’s a good chance you’re already using Postman to test, debug, and manage collections. When collaborating with teams, especially Android or iOS developers, you often need to share your API documentation. This typically involves sharing the Postman collection in JSON format along with manually written documentation to describe the API.\u003c/p\u003e","title":"Generate API Documentation Easily with Docgen: A Simple, Open-Source Tool"},{"content":"\nDevelopers often need to consume JSON data from other services and query over it. However, querying JSON data can be time-consuming. Over the past few days, I’ve been working on a Golang package to make querying JSON data easier. The idea and inspiration for this package come from PHP-JSONQ by Nahid Bin Azhar. Let’s start by looking at a sample JSON dataset:\nNow that we have the JSON data, let’s dive into some examples of how to query it using the package.\nExample 1 Query: select * from vendor.items where price \u0026gt; 1200 or id null Using gojsonq we can do the query like:\nExample 2 Query: select name, price from vendor.items where price \u0026gt; 1200 or id null Using gojsonq we can do the query like:\nExample 3 Query: select sum(price) from vendor.items where price \u0026gt; 1200 or id null Using gojsonq we can do the query like:\nNote you can use other aggregation function like Min/Max/Avg/Count\n###Example 4 Query: select price from vendor.items where price \u0026gt; 1200 Using gojsonq we can do the query like:\nNote: You\u0026rsquo;ll get a plain array of price\nExample 5 Query: select * from vendor.items order by price Using gojsonq we can do the query like:\nExample 6 Query: select description from . Using gojsonq we can do the query like:\nThe package also includes several other useful methods. Please note that the package is still under active development! If you have any suggestions or encounter any bugs, feel free to open an issue.\nIf you like the concept, don’t forget to give it a STAR!\nGitHub Link for gojsonq\nThank you very much for reading the article!\n","permalink":"https://devrx.io/posts/gojsonq/","summary":"\u003cp\u003e\u003cimg alt=\"gojsonq-logo\" loading=\"lazy\" src=\"/media/posts/gojsonq/gojsonq.jpeg\"\u003e\u003c/p\u003e\n\u003cp\u003eDevelopers often need to consume JSON data from other services and query over it. However, querying JSON data can be time-consuming. Over the past few days, I’ve been working on a Golang package to make querying JSON data easier. The idea and inspiration for this package come from PHP-JSONQ by Nahid Bin Azhar. Let’s start by looking at a sample JSON dataset:\u003c/p\u003e\n\u003cscript src=\"https://gist.github.com/thedevsaddam/ee7f25adb9f4278ce0ef37b8d28bed98.js\"\u003e\u003c/script\u003e\n\n\u003cp\u003eNow that we have the JSON data, let’s dive into some examples of how to query it using the package.\u003c/p\u003e","title":"Query JSON data using Golang (gojsonq package)"},{"content":"\nGenerally, Go is perfect for building microservices, but that doesn’t mean building a simple MVC app is difficult. Go has built-in support for parsing HTML templates, although we won’t focus on that in this case.\nFirst, let’s write the Go code to serve an HTML page and save it in a directory.\nIn this example, let’s create a directory called todoapp and inside it, create a home.tpl file. Paste the HTML content in home.tpl, which will make an HTTP call to our backend application.\nI won’t go into detail about the template and the Vue.js code written in the home.tpl file in this article.\nNow, let’s start building the backend. Create a main.go file inside the same directory where home.tpl is located.\nWe will be using the chi router for routing, mgo for MongoDB to persist our data, and renderer to render the responses. You can install these packages using go get. Here’s the command:\n$ go get github.com/go-chi/chi $ go get gopkg.in/mgo.v2 $ go get github.com/thedevsaddam/renderer Now, let’s start writing our code. Open the main.go file in your favorite editor.\nFirst, we’ll initialize the essential constants and variables, and create some types to use in our application. Here’s how you can set it up:\nLet’s walk through the above example. Between lines 4–9, we declared a constant block to define essential constants such as the hostname, database name, port, etc.\nBetween lines 11–15, we declared two structs, Todo and TodoModel. Both structs have the same number of fields, and the field names are identical. However, in TodoModel, the ID field is of type bson.ObjectId. We used the bson tag so that the mgo package can work with these tags. In contrast, the Todo struct uses the json tag to allow the JSON decoder to properly serialize the Go type into typical JSON.\nIf you examine the example, you’ll notice that the first two lines, where we declared two variables. The first variable is used to hold a pointer to the renderer.Render type, and the second holds a pointer to the mgo.Database. These variables are initialized between lines 27–33.\nNow, let’s proceed to part two of the code.\nIf you take a look at the example above, between lines 1–4, we wrote a function called homeHandler which renders our home page using the render package.\nBetween lines 6–37, we wrote the main function, which serves as the entry point for the application. Inside the main function, at line 7, we created a channel of type os.Signal. At line 8, we registered this channel with the os.Signal package, specifying os.Interrupt as the argument. This essentially listens for OS signals, such as when the user interrupts (e.g., by pressing Ctrl+C), and notifies the channel. We use this signal to gracefully shut down our server.\nAt line 10, we declare and initialize a chi router variable. At line 11, we apply the Logger middleware, which comes with the chi router as a sub-package, to log incoming requests to stdout.\nAt line 16, we declared an http.Server variable named server and initialized it using a struct literal. Between lines 24–29, we start a goroutine to launch the server. At line 31, we release the signal from the blocked channel, and at line 33, we declare a context with a 5-second timeout, passing it to the server’s Shutdown method. At line 35, we use the defer statement, ensuring that as soon as the main function ends, the deferred cancel function is called to release the context resources.\nAt line 14, we mount a route group called todo, and between lines 39–48, we register a route group that contains four routes.\nNow, let’s move on to the third part of the code.\nIn the example above, between lines 1–36, we wrote the createTodo function, which is responsible for creating a new todo item. At line 2, we declared a variable of type Todo, and between lines 4–7, we decoded the incoming JSON data into the t variable. If the decoding fails, we return a JSON response to the user using the renderer.JSON() method. Between lines 10–15, we check if the title is empty and, if so, send a JSON response indicating the error. At line 18, we declared the tm variable and initialized it using the struct literal with data from the t variable and other relevant information. Between lines 24–30, we insert the data into MongoDB. Finally, at line 76, we send a JSON reply to the user, confirming the creation of the todo with the generated todo_id.\nThe updateTodo and deleteTodo functions follow a similar structure. When fetching the todo list from MongoDB, we use the fetchTodos function. Between lines 94–102, we transform the fetched todoModel data into the Todo type and send the list to the consumer in JSON format. And that’s it!\nAs you can see, I wrote this article in a somewhat random order to tell you the story. It may be challenging for beginners to write the full source code and get it running correctly, but don’t worry here is the full source code. Clone it to your $GOPATH/src directory and run the go get . command to install the dependencies.\nIf you enjoyed this article, feel free to follow me on GitHub, hit the appreciate button, and share the article with others. Thank you!\n","permalink":"https://devrx.io/posts/lets-make-a-simple-todo-app-with-go/","summary":"\u003cp\u003e\u003cimg alt=\"todo application\" loading=\"lazy\" src=\"/media/posts/lets-make-a-simple-todo-app-with-Go/todo-app.png\"\u003e\u003c/p\u003e\n\u003cp\u003eGenerally, Go is perfect for building microservices, but that doesn’t mean building a simple MVC app is difficult. Go has built-in support for parsing HTML templates, although we won’t focus on that in this case.\u003c/p\u003e\n\u003cp\u003eFirst, let’s write the Go code to serve an HTML page and save it in a directory.\u003c/p\u003e\n\u003cp\u003eIn this example, let’s create a directory called todoapp and inside it, create a home.tpl file. Paste the HTML content in home.tpl, which will make an HTTP call to our backend application.\u003c/p\u003e","title":"Let’s make a simple todo app with Go"},{"content":"When building REST APIs or web applications in Go, one of the essential tasks is validating incoming request data. Having worked on various small to medium-sized projects in Golang—most of which are microservices providing RESTful APIs—I’ve employed several approaches to handle data validation.\nAmong these, there’s one method I frequently rely on. For validating application/json or text/plain requests, I begin by defining a struct type to represent the specific request payload. Then, I implement a Validate method on that struct to encapsulate the validation logic.\nThis approach is my first choice when handling JSON payloads. However, for other types of input—such as form-data, query strings, or x-www-form-urlencoded requests—the process differs slightly.\nFor more complex validation scenarios, I often use the govalidator library. While it provides extensive features, I’ve found that it can sometimes take more effort to validate requests than to implement the business logic itself. Additionally, whenever validation rules change, updating the corresponding error messages can become tedious.\nTo address these challenges, I developed a simple validation package for handling request validation in Golang more efficiently. Here’s a look at how it works:\nThis approach is cleaner and simpler, making it easy to modify validation rules as needed. If you require a custom validation rule—such as checking for a unique username—you can effortlessly integrate it into the system. Adding custom rules is straightforward, allowing you to tailor validations to your specific requirements.\nHere’s an example of how to add a custom rule:\nAdding custom rules is straightforward, but I’m still exploring the best practices for request validation. Using struct tags or strings to define validation rules often feels limiting and inflexible, especially for more complex scenarios. I hope the Go community will come up with more robust and elegant solutions for validating incoming requests in the future.\nI’d love to hear your thoughts on this topic. What approaches do you prefer for request validation in Go or other languages? How do you strike a balance between simplicity and flexibility in your validation logic?\n","permalink":"https://devrx.io/posts/an-easy-way-to-validate-golang-request/","summary":"\u003cp\u003eWhen building REST APIs or web applications in Go, one of the essential tasks is validating incoming request data. Having worked on various small to medium-sized projects in Golang—most of which are microservices providing RESTful APIs—I’ve employed several approaches to handle data validation.\u003c/p\u003e\n\u003cp\u003eAmong these, there’s one method I frequently rely on. For validating application/json or text/plain requests, I begin by defining a struct type to represent the specific request payload. Then, I implement a Validate method on that struct to encapsulate the validation logic.\u003c/p\u003e","title":"An easy way to validate Go request"},{"content":"Today, I’m going to build a simple API for a to-do application using the Go programming language. For this, I’ll use Gin, one of Go’s simplest and fastest web frameworks, and Gorm, a powerful and flexible ORM for database operations.\nTo get started, you’ll need to install these packages. Navigate to your workspace directory ($GOPATH/src) and run the following commands:\n$ go get gopkg.in/gin-gonic/gin.v1 $ go get -u github.com/jinzhu/gorm $ go get github.com/go-sql-driver/mysql In generic crud application we need the API’s as follows:\nPOST todos/ GET todos/ GET todos/{id} PUT todos/{id} DELETE todos/{id} Let’s start coding! First, navigate to your $GOPATH/src directory and create a folder named todo. Inside the todo directory, create a new file called main.go.\nNow, import the Gin framework into your project and set up the routes. I prefer to add a version prefix like api/v1/ to the API endpoints, so we’ll use Gin’s Group method to organize the routes. Here’s how your main.go file should look:\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { router := gin.Default() v1 := router.Group(\u0026#34;/api/v1/todos\u0026#34;) { v1.POST(\u0026#34;/\u0026#34;, createTodo) v1.GET(\u0026#34;/\u0026#34;, fetchAllTodo) v1.GET(\u0026#34;/:id\u0026#34;, fetchSingleTodo) v1.PUT(\u0026#34;/:id\u0026#34;, updateTodo) v1.DELETE(\u0026#34;/:id\u0026#34;, deleteTodo) } router.Run() } Now that we’ve created five routes to handle functions like createTodo, fetchAllTodo, etc., let’s set up the database connection. We’ll use Gorm as our ORM and the MySQL dialect for database operations.\npackage main import ( \u0026#34;github.com/jinzhu/gorm\u0026#34; _ \u0026#34;github.com/jinzhu/gorm/dialects/mysql\u0026#34; ) var db *gorm.DB func init() { //open a db connection var err error db, err = gorm.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:12345@/demo?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;) if err != nil { panic(\u0026#34;failed to connect database\u0026#34;) } //Migrate the schema db.AutoMigrate(\u0026amp;todoModel{}) } In the code above, the \u0026ldquo;mysql\u0026rdquo; is our database driver, \u0026ldquo;root\u0026rdquo; is the database username, \u0026ldquo;12345\u0026rdquo; is the password, \u0026ldquo;demo\u0026rdquo; is the database name. Feel free to replace these values with your specific database configuration.\nWe’ll use a Database function to manage the database connection, making it reusable across the application. Additionally, let’s create two structs:\ntodoModel: Represents the original Todo data as stored in the database. transformedTodo: Represents the API response format, excluding fields like created_at and updated_at, which should not be exposed to consumers. type ( // todoModel describes a todoModel type todoModel struct { gorm.Model Title string `json:\u0026#34;title\u0026#34;` Completed int `json:\u0026#34;completed\u0026#34;` } // transformedTodo represents a formatted todo transformedTodo struct { ID uint `json:\u0026#34;id\u0026#34;` Title string `json:\u0026#34;title\u0026#34;` Completed bool `json:\u0026#34;completed\u0026#34;` } ) The Todo struct has an additional field called gorm.Model. This field embeds the Model struct, which contains four fields: ID, CreatedAt, UpdatedAt, and DeletedAt.\nGorm provides migration facilities, which we have already used in the init function. When we run the application, it will first establish the database connection, and then perform the migration. This ensures that the necessary database tables are created or updated based on the struct definitions.\n//Migrate the schema db.AutoMigrate(\u0026amp;todoModel{}) Do you remember the five routes we defined earlier? Let’s implement the five methods one by one.\nWhen a user sends a POST request to the path api/v1/todos/ with the title and completed fields, it will be handled by the createTodo function in the route v1.POST(\u0026quot;/\u0026quot; , createTodo).\nLet’s now implement the createTodo function.\n// createTodo add a new todo func createTodo(c *gin.Context) { completed, _ := strconv.Atoi(c.PostForm(\u0026#34;completed\u0026#34;)) todo := todoModel{Title: c.PostForm(\u0026#34;title\u0026#34;), Completed: completed} db.Save(\u0026amp;todo) c.JSON(http.StatusCreated, gin.H{\u0026#34;status\u0026#34;: http.StatusCreated, \u0026#34;message\u0026#34;: \u0026#34;Todo item created successfully!\u0026#34;, \u0026#34;resourceId\u0026#34;: todo.ID}) } In the code above, we use the Gin Context to receive the posted data and the Gorm database connection to save the todo. After saving the resource, we send the resource ID back to the user along with a meaningful and informative response.\nNow, let’s implement the remaining functions.\n// fetchAllTodo fetch all todos func fetchAllTodo(c *gin.Context) { var todos []todoModel var _todos []transformedTodo db.Find(\u0026amp;todos) if len(todos) \u0026lt;= 0 { c.JSON(http.StatusNotFound, gin.H{\u0026#34;status\u0026#34;: http.StatusNotFound, \u0026#34;message\u0026#34;: \u0026#34;No todo found!\u0026#34;}) return } //transforms the todos for building a good response for _, item := range todos { completed := false if item.Completed == 1 { completed = true } else { completed = false } _todos = append(_todos, transformedTodo{ID: item.ID, Title: item.Title, Completed: completed}) } c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: http.StatusOK, \u0026#34;data\u0026#34;: _todos}) } // fetchSingleTodo fetch a single todo func fetchSingleTodo(c *gin.Context) { var todo todoModel todoID := c.Param(\u0026#34;id\u0026#34;) db.First(\u0026amp;todo, todoID) if todo.ID == 0 { c.JSON(http.StatusNotFound, gin.H{\u0026#34;status\u0026#34;: http.StatusNotFound, \u0026#34;message\u0026#34;: \u0026#34;No todo found!\u0026#34;}) return } completed := false if todo.Completed == 1 { completed = true } else { completed = false } _todo := transformedTodo{ID: todo.ID, Title: todo.Title, Completed: completed} c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: http.StatusOK, \u0026#34;data\u0026#34;: _todo}) } // updateTodo update a todo func updateTodo(c *gin.Context) { var todo todoModel todoID := c.Param(\u0026#34;id\u0026#34;) db.First(\u0026amp;todo, todoID) if todo.ID == 0 { c.JSON(http.StatusNotFound, gin.H{\u0026#34;status\u0026#34;: http.StatusNotFound, \u0026#34;message\u0026#34;: \u0026#34;No todo found!\u0026#34;}) return } db.Model(\u0026amp;todo).Update(\u0026#34;title\u0026#34;, c.PostForm(\u0026#34;title\u0026#34;)) completed, _ := strconv.Atoi(c.PostForm(\u0026#34;completed\u0026#34;)) db.Model(\u0026amp;todo).Update(\u0026#34;completed\u0026#34;, completed) c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: http.StatusOK, \u0026#34;message\u0026#34;: \u0026#34;Todo updated successfully!\u0026#34;}) } // deleteTodo remove a todo func deleteTodo(c *gin.Context) { var todo todoModel todoID := c.Param(\u0026#34;id\u0026#34;) db.First(\u0026amp;todo, todoID) if todo.ID == 0 { c.JSON(http.StatusNotFound, gin.H{\u0026#34;status\u0026#34;: http.StatusNotFound, \u0026#34;message\u0026#34;: \u0026#34;No todo found!\u0026#34;}) return } db.Delete(\u0026amp;todo) c.JSON(http.StatusOK, gin.H{\u0026#34;status\u0026#34;: http.StatusOK, \u0026#34;message\u0026#34;: \u0026#34;Todo deleted successfully!\u0026#34;}) } In the fetchAllTodos function, we fetch all the todos and build a transformed response with only the id, title, and completed fields. We exclude the CreatedAt, UpdatedAt, and DeletedAt fields, and we cast the integer value of Completed to a boolean.\nNow that we’ve written enough code, let’s build the app and test it. I will test it using the Postman Chrome extension (you can use any REST client like curl to test).\nTo build the app, open your terminal and navigate to the project directory.\n$ go build main.go The command will build a binary file main and to run the file us this command $ ./main . Wow, our simple todo app is running on port: 8080. It’ll display the debug log, because by default gin run’s in debug mode and port 8080.\nNeed full source code? ","permalink":"https://devrx.io/posts/build-restful-api-service-in-go/","summary":"\u003cp\u003eToday, I’m going to build a simple API for a to-do application using the Go programming language. For this, I’ll use Gin, one of Go’s simplest and fastest web frameworks, and Gorm, a powerful and flexible ORM for database operations.\u003c/p\u003e\n\u003cp\u003eTo get started, you’ll need to install these packages. Navigate to your workspace directory ($GOPATH/src) and run the following commands:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ go get gopkg.in/gin-gonic/gin.v1\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ go get -u github.com/jinzhu/gorm\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ go get github.com/go-sql-driver/mysql\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIn generic crud application we need the API’s as follows:\u003c/p\u003e","title":"Build RESTful API service in golang using gin-gonic framework"},{"content":"When building APIs with Laravel, enabling throttling is essential to protect your endpoints from scraping or other malicious activities. By default, Laravel’s throttle middleware limits API requests and responds with an HTML message containing “Too Many Attempts” when the limit is exceeded.\nTo customize this response—for instance, returning a JSON-formatted error message—you can follow these steps:\nCreate a new file named ThrottleRequestsMiddleware.php in the app/Http/Middleware/ directory. Paste the following code into the newly created file: \u0026lt;?php namespace App\\Http\\Middleware; use Closure; use Illuminate\\Cache\\RateLimiter; use Symfony\\Component\\HttpFoundation\\Response; class ThrottleRequestsMiddleware { /** * The rate limiter instance. * * @var \\Illuminate\\Cache\\RateLimiter */ protected $limiter; /** * Create a new request throttler. * * @param \\Illuminate\\Cache\\RateLimiter $limiter */ public function __construct(RateLimiter $limiter) { $this-\u0026gt;limiter = $limiter; } /** * Handle an incoming request. * * @param \\Illuminate\\Http\\Request $request * @param \\Closure $next * @param int $maxAttempts * @param int $decayMinutes * @return mixed */ public function handle($request, Closure $next, $maxAttempts = 60, $decayMinutes = 1) { $key = $this-\u0026gt;resolveRequestSignature($request); if ($this-\u0026gt;limiter-\u0026gt;tooManyAttempts($key, $maxAttempts, $decayMinutes)) { return $this-\u0026gt;buildResponse($key, $maxAttempts); } $this-\u0026gt;limiter-\u0026gt;hit($key, $decayMinutes); $response = $next($request); return $this-\u0026gt;addHeaders( $response, $maxAttempts, $this-\u0026gt;calculateRemainingAttempts($key, $maxAttempts) ); } /** * Resolve request signature. * * @param \\Illuminate\\Http\\Request $request * @return string */ protected function resolveRequestSignature($request) { return $request-\u0026gt;fingerprint(); } /** * Create a \u0026#39;too many attempts\u0026#39; response. * * @param string $key * @param int $maxAttempts * @return \\Illuminate\\Http\\Response */ protected function buildResponse($key, $maxAttempts) { $message = json_encode([ \u0026#39;error\u0026#39; =\u0026gt; [ \u0026#39;message\u0026#39; =\u0026gt; \u0026#39;Too many attempts, please slow down the request.\u0026#39; //may comes from lang file ], \u0026#39;status\u0026#39; =\u0026gt; 4029 //your custom code ]); $response = new Response($message, 429); $retryAfter = $this-\u0026gt;limiter-\u0026gt;availableIn($key); return $this-\u0026gt;addHeaders( $response, $maxAttempts, $this-\u0026gt;calculateRemainingAttempts($key, $maxAttempts, $retryAfter), $retryAfter ); } /** * Add the limit header information to the given response. * * @param \\Symfony\\Component\\HttpFoundation\\Response $response * @param int $maxAttempts * @param int $remainingAttempts * @param int|null $retryAfter * @return \\Illuminate\\Http\\Response */ protected function addHeaders(Response $response, $maxAttempts, $remainingAttempts, $retryAfter = null) { $headers = [ \u0026#39;X-RateLimit-Limit\u0026#39; =\u0026gt; $maxAttempts, \u0026#39;X-RateLimit-Remaining\u0026#39; =\u0026gt; $remainingAttempts, ]; if (!is_null($retryAfter)) { $headers[\u0026#39;Retry-After\u0026#39;] = $retryAfter; $headers[\u0026#39;Content-Type\u0026#39;] = \u0026#39;application/json\u0026#39;; } $response-\u0026gt;headers-\u0026gt;add($headers); return $response; } /** * Calculate the number of remaining attempts. * * @param string $key * @param int $maxAttempts * @param int|null $retryAfter * @return int */ protected function calculateRemainingAttempts($key, $maxAttempts, $retryAfter = null) { if (!is_null($retryAfter)) { return 0; } return $this-\u0026gt;limiter-\u0026gt;retriesLeft($key, $maxAttempts); } } Then go to your kernel.php file in app/Http/ directory and replace\n\u0026#39;throttle\u0026#39; =\u0026gt; \\Illuminate\\Routing\\Middleware\\ThrottleRequests::class, with\n\u0026#39;throttle\u0026#39; =\u0026gt; \\App\\Middleware\\ThrottleRequestsMiddleware::class, Note: While you can extend the base ThrottleRequests class and override only the necessary methods for a cleaner implementation, let’s be honest—I’m too lazy for that! The straightforward copy-paste approach works just as well and gets the job done quickly.\nHopefully, this solution will work just fine for your needs! 😊\n","permalink":"https://devrx.io/posts/how-to-customize-laravel-request-throttle-message-in-api-response/","summary":"\u003cp\u003eWhen building APIs with Laravel, enabling throttling is essential to protect your endpoints from scraping or other malicious activities. By default, Laravel’s throttle middleware limits API requests and responds with an HTML message containing “Too Many Attempts” when the limit is exceeded.\u003c/p\u003e\n\u003cp\u003eTo customize this response—for instance, returning a JSON-formatted error message—you can follow these steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCreate a new file named ThrottleRequestsMiddleware.php in the app/Http/Middleware/ directory.\u003c/li\u003e\n\u003cli\u003ePaste the following code into the newly created file:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-php\" data-lang=\"php\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e\u0026lt;?\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ephp\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003enamespace\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eApp\\Http\\Middleware\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003euse\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eClosure\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003euse\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eIlluminate\\Cache\\RateLimiter\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003euse\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eSymfony\\Component\\HttpFoundation\\Response\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eThrottleRequestsMiddleware\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e{\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * The rate limiter instance.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @var \\Illuminate\\Cache\\RateLimiter\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eprotected\u003c/span\u003e $limiter;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * Create a new request throttler.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  \\Illuminate\\Cache\\RateLimiter $limiter\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e __construct(\u003cspan style=\"color:#a6e22e\"\u003eRateLimiter\u003c/span\u003e $limiter)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003elimiter\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e $limiter;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * Handle an incoming request.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  \\Illuminate\\Http\\Request $request\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  \\Closure $next\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int $maxAttempts\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int $decayMinutes\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @return mixed\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ehandle\u003c/span\u003e($request, \u003cspan style=\"color:#a6e22e\"\u003eClosure\u003c/span\u003e $next, $maxAttempts \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e60\u003c/span\u003e, $decayMinutes \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $key \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eresolveRequestSignature\u003c/span\u003e($request);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e ($this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003elimiter\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003etooManyAttempts\u003c/span\u003e($key, $maxAttempts, $decayMinutes)) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ebuildResponse\u003c/span\u003e($key, $maxAttempts);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003elimiter\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ehit\u003c/span\u003e($key, $decayMinutes);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $response \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e $next($request);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eaddHeaders\u003c/span\u003e(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $response, $maxAttempts,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ecalculateRemainingAttempts\u003c/span\u003e($key, $maxAttempts)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        );\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * Resolve request signature.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  \\Illuminate\\Http\\Request $request\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @return string\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eprotected\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eresolveRequestSignature\u003c/span\u003e($request)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e $request\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003efingerprint\u003c/span\u003e();\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * Create a \u0026#39;too many attempts\u0026#39; response.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  string $key\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int $maxAttempts\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @return \\Illuminate\\Http\\Response\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eprotected\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ebuildResponse\u003c/span\u003e($key, $maxAttempts)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $message \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ejson_encode\u003c/span\u003e([\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;error\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e=\u0026gt;\u003c/span\u003e [\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e                \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;message\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Too many attempts, please slow down the request.\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e//may comes from lang file\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e            ],\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;status\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e=\u0026gt;\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e4029\u003c/span\u003e \u003cspan style=\"color:#75715e\"\u003e//your custom code\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e        ]);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $response \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enew\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eResponse\u003c/span\u003e($message, \u003cspan style=\"color:#ae81ff\"\u003e429\u003c/span\u003e);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $retryAfter \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003elimiter\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eavailableIn\u003c/span\u003e($key);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eaddHeaders\u003c/span\u003e(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $response, $maxAttempts,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ecalculateRemainingAttempts\u003c/span\u003e($key, $maxAttempts, $retryAfter),\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $retryAfter\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        );\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * Add the limit header information to the given response.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  \\Symfony\\Component\\HttpFoundation\\Response $response\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int $maxAttempts\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int $remainingAttempts\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int|null $retryAfter\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @return \\Illuminate\\Http\\Response\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eprotected\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eaddHeaders\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003eResponse\u003c/span\u003e $response, $maxAttempts, $remainingAttempts, $retryAfter \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enull\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $headers \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e [\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;X-RateLimit-Limit\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e=\u0026gt;\u003c/span\u003e $maxAttempts,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;X-RateLimit-Remaining\u0026#39;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e=\u0026gt;\u003c/span\u003e $remainingAttempts,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        ];\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e (\u003cspan style=\"color:#f92672\"\u003e!\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eis_null\u003c/span\u003e($retryAfter)) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $headers[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Retry-After\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e $retryAfter;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            $headers[\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;Content-Type\u0026#39;\u003c/span\u003e] \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;application/json\u0026#39;\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        $response\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eheaders\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eadd\u003c/span\u003e($headers);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e $response;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#e6db74\"\u003e/**\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * Calculate the number of remaining attempts.\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     *\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  string $key\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int $maxAttempts\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @param  int|null $retryAfter\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     * @return int\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e     */\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eprotected\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efunction\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ecalculateRemainingAttempts\u003c/span\u003e($key, $maxAttempts, $retryAfter \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enull\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e (\u003cspan style=\"color:#f92672\"\u003e!\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eis_null\u003c/span\u003e($retryAfter)) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e $this\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003elimiter\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e-\u0026gt;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003eretriesLeft\u003c/span\u003e($key, $maxAttempts);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThen go to your \u003ccode\u003ekernel.php\u003c/code\u003e file in \u003cem\u003eapp/Http/\u003c/em\u003e directory and replace\u003c/p\u003e","title":"How to customize Laravel request throttle message in API response?"}]